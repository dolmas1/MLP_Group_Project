classifier:

  embeddings:
    embeddings: "roberta-base"    # roberta-base or bert-base-cased or prajjwal1/bert-medium
    tokenizer: "roberta-base"     # roberta-base or bert-base-cased or prajjwal1/bert-medium

  model:
  
    epochs: 100
    batch_size: 4
    positive_class_weight: 1
    early_stopping: 10
    random_seed: 121

    destination_path: "../results/roberta3"
    
  data:
    path: "../data/hatespeech"
    train_file: "train.csv"
    dev_file: "dev.csv"
    test_file: "test.csv"

 
